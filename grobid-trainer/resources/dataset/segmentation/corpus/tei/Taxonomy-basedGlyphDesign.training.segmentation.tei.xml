<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front> Taxonomy-Based Glyph Design — with a Case Study on <lb/>Visualizing Workflows of Biological Experiments <lb/> Eamonn Maguire, Philippe Rocca-Serra, Susanna-Assunta Sansone, Jim Davies, and Min Chen <lb/> Saccharomyces cerevisiae FY1679 <lb/>NZ_0hrs_Grow_1 <lb/>growth <lb/>mRNA extraction <lb/>NZ_0hrs_Sample_1_Extract <lb/>NZ_1hrs_Drug_Sample_1_Extract <lb/>NZ_2hrs_Drug_Sample_1_Extract <lb/>NZ_4hrs_Drug_Sample_1_Extract <lb/>NZ_2hrs_Vehicle_Sample_1_Extract <lb/>NZ_4hrs_Vehicle_Sample_1_Extract <lb/>NZ_4hrs_Vehicle_Sample_1_Extract <lb/>biotin labeling <lb/>biotin labeling <lb/>biotin labeling <lb/>biotin labeling <lb/>biotin labeling <lb/>biotin labeling <lb/>biotin labeling <lb/> NZ_0hrs_Sample_1_Labeled <lb/>NZ_1hrs_Drug_Sample_1_Extract_Labeled <lb/>NZ_2hrs_Drug_Sample_1_Extract_Labeled <lb/>NZ_4hrs_Drug_Sample_1_Extract_Labeled <lb/>NZ_2hrs_Vehicle_Sample_1_Extract_Labeled <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled <lb/> mRNA extraction <lb/>mRNA extraction <lb/>mRNA extraction <lb/>mRNA extraction <lb/>mRNA extraction <lb/>mRNA extraction <lb/>biotin <lb/>biotin <lb/>biotin <lb/>biotin <lb/>biotin <lb/>biotin <lb/>biotin <lb/>hybridization <lb/>hybridization <lb/>hybridization <lb/>hybridization <lb/>hybridization <lb/>hybridization <lb/>hybridization <lb/> NZ_0hrs_Sample_1_Labeled_Hyb1 <lb/>NZ_1hrs_Drug_Sample_1_Extract_Labeled_Hyb3 <lb/>NZ_2hrs_Drug_Sample_1_Extract_Labeled_Hyb7 <lb/>NZ_4hrs_Drug_Sample_1_Extract_Labeled_Hyb11 <lb/>NZ_2hrs_Vehicle_Sample_1_Extract_Labeled_Hyb9 <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled_Hyb13 <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled_Hyb5 <lb/> scanning <lb/>scanning <lb/>scanning <lb/>scanning <lb/>scanning <lb/>scanning <lb/>scanning <lb/> NZ_0hrs_Sample_1_Labeled_Hyb1_Scan1 <lb/>NZ_1hrs_Drug_Sample_1_Extract_Labeled_Hyb3_Scan3 <lb/>NZ_2hrs_Drug_Sample_1_Extract_Labeled_Hyb7_Scan7 <lb/>NZ_4hrs_Drug_Sample_1_Extract_Labeled_Hyb11_Scan11 <lb/>NZ_2hrs_Vehicle_Sample_1_Extract_Labeled_Hyb9_Scan9 <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled_Hyb13_Scan13 <lb/>NZ_4hrs_Vehicle_Sample_1_Extract_Labeled_Hyb5_Scan5 <lb/> feature extraction <lb/>feature extraction <lb/>feature extraction <lb/>feature extraction <lb/>feature extraction <lb/>feature extraction <lb/>feature extraction <lb/> E-MAXD-4-raw-data-426648549.txt <lb/>E-MAXD-4-raw-data-426648567.txt <lb/>E-MAXD-4-raw-data-426648585.txt <lb/>E-MAXD-4-raw-data-426648603.txt <lb/>E-MAXD-4-raw-data-426648639.txt <lb/>E-MAXD-4-raw-data-426648657.txt <lb/>E-MAXD-4-raw-data-426648621.txt <lb/> data processing <lb/>data processing <lb/>data processing <lb/>data processing <lb/>data processing <lb/>data processing <lb/>data processing <lb/> E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/>E-MAXD-4-processed-data-1342566476.txt <lb/> Fig. 1. a) Workflow as rendered currently using toolkits such as GraphViz. b) We propose to replace the textual labels with glyphs, <lb/>while allowing interactive access to detailed descriptions. This makes it easy to gain an overview, search components and compare <lb/>workflows. The screenshot shows a prototype developed within ISAcreator, a system for capturing biological experiment metadata. <lb/> Abstract—Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed <lb/>and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers&apos; experience <lb/>and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large <lb/>number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph <lb/>design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual <lb/>channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective <lb/>means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological <lb/>experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy <lb/>with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors. <lb/> Index Terms—Glyph-based techniques, taxonomies, design methodologies, bioinformatics visualization. <lb/></front>

			<body> 1 INTRODUCTION <lb/> Glyph-based visualization is a class of visual representations where a <lb/>collection of small visual objects (referred to as glyphs) are used to <lb/>encode different attribute dimensions of an input data space. A good <lb/>glyph design can enable users to conduct visual search more efficiently <lb/>during interactive visualization, and facilitate effective learning, mem-<lb/>orizing and using the visual encoding scheme. A less effective visual <lb/>design may suffer from various shortcomings such as being percep-<lb/>tually confusing, semantically ambiguous, difficult to learn and re-<lb/>member, or unable to accommodate low-resolution display devices. <lb/></body>

			<front> • Eamonn Maguire is with Oxford e-Research Centre and Department of <lb/>Computer Science, University of Oxford, UK. E-mail: <lb/>eamonn.maguire@st-annes.ox.ac.uk. <lb/> • Philippe Rocca-Serra, Susanna-Assunta Sansone and Min Chen are with <lb/>Oxford e-Research Centre, University of Oxford, UK. E-mail: {philippe. <lb/> rocca-serra,susanna-assunta.sansone,min.chen}@oerc.ox.ac.uk. <lb/> • Jim Davies is with Department of Computer Science, University of Oxford, <lb/>UK. E-mail: jim.davies@cs.ox.ac.uk. <lb/>Manuscript received 31 March 2012; accepted 1 August 2012; posted online <lb/>14 October 2012; mailed on 5 October 2012. <lb/>For information on obtaining reprints of this article, please send <lb/>e-mail to: tvcg@computer.org. <lb/></front>

			<body> Most accepted designs have undergone an enduring process of evolu-<lb/>tion, refinement and standardization. One could not and should not <lb/>remove the necessity for such processes in glyph design. Meanwhile, <lb/>the design process for a glyph set usually relies on an assortment of <lb/>creativity, artistic skill, domain knowledge, intuition about users, and <lb/>sometimes personal preference. While most of these qualities are ab-<lb/>solutely helpful and some are inevitable, it is highly desirable to intro-<lb/>duce &quot; systematicism &quot; and objectivity into the design process. <lb/>To demonstrate our approach, we elected the field of experimental <lb/>biology as a test bed for developing a systematic methodology to cre-<lb/>ate a glyph-based visual mapping for visualizing experimental design <lb/>and experimental processes. While experimental design is at the heart <lb/>of biological data evidence gathering, representation of such informa-<lb/>tion is confined to either verbose description or ineffective represen-<lb/>tations. This claim is backed by a survey of public biodata repos-<lb/>itories, devised to ensure data perennity, scientific scrutiny and re-<lb/>producibility. As illustrated in Fig. 1(a), workflows are traditionally <lb/>drawn as text-based diagrams. Text labels are indices of concepts, and <lb/>usually they do not encode multivariate information directly. Text-<lb/>labeled boxes are costly in terms of display space usage as well as <lb/>time required for visual search since parsing and interpretation of text <lb/>is a slow post-attentive process [59]. They are particularly ineffective <lb/>when one needs to compare between different workflows or to identify <lb/>unusual or missing components in a workflow. <lb/>Therefore, exploring an alternative in the form of glyph based rep-<lb/> resentations, which are at the core of many successful schematic dia-<lb/>grams in the history of sciences, engineering and business manage-<lb/>ment, offers a potentially more effective means for depicting these <lb/>workflows. This presents us with an interesting case study where other <lb/>types of design approaches would not be appropriate, especially in <lb/>dealing with several hundreds of conceptual names. <lb/>It is important to note that domain experts are in general more will-<lb/>ing and able to learn and memorize an encoding scheme in order to im-<lb/>prove the accuracy and efficiency of routine tasks. At the same time, it <lb/>is also necessary for an encoding scheme to facilitate effective learning <lb/>and remembering through appropriate abstraction and metaphors. <lb/>Motivated by this case study, we made an observation that when <lb/>a large number of concepts (or taxa) are organized into a taxonomic <lb/>tree, the hierarchy typically represents an ordering of different cat-<lb/>egorization schemes. The schemes that are higher-up in the taxon-<lb/>omy (closer to the root) are usually considered to be more important, <lb/>which reflect their conceptual coverage, frequency of usage, domain-<lb/>specific convention, and some other measurable factors. In terms of <lb/>visual encoding, higher up schemes should ideally be mapped to vi-<lb/>sual channels that have more discriminative capacity. Hence, we can <lb/>explore the parallel between the taxonomic hierarchy and the order-<lb/>ing of visual channels based on discriminative capacity to formulate a <lb/>systematic and relatively objective process for designing a glyph set. <lb/>This approach addresses one of the most common criticisms of data <lb/>glyphs: the data to visual attribute mapping bias [58]. Given a large <lb/>data repository that encompasses many concepts, our design process is <lb/>composed of four major steps: (i) gathering and processing raw meta-<lb/>data for obtaining a set of taxa (names); (ii) formulating a taxonomy <lb/>based on a set of categorization schemes (Section 4); (iii) carrying <lb/>out visual design, which includes the sub-process of determining the <lb/>ordering of visual channels, proposing optional visual mappings, and <lb/>identifying metaphoric abstractions and associations (Section 5); and <lb/>(iv) implementing a glyph-based visualization system, in our case, for <lb/>depicting workflows of biological experiments (Section 6). <lb/>Similar to most design processes, it is helpful to conduct all stages <lb/>in a progressive and iterative manner. As glyph-based visualization is <lb/>normally deployed in a specific application domain, it is important to <lb/>involve domain experts at every stage of the design process. During <lb/>this work, we met with domain specialists on a weekly basis. <lb/> 2 RELATED WORK <lb/> In this section, we give a brief overview of two most relevant areas <lb/>in visualization, glyph-based visualization and workflow visualiza-<lb/>tion. The remainder background information includes the biological <lb/>data management, perceptual guidance, and categorization algorithms, <lb/>which will be described in the following sections where the relevant <lb/>technical details are discussed. <lb/> 2.1 Glyph-based Visualization <lb/> There are many examples of glyph usage in the literature spanning <lb/>many disciplines, especially in conjunction with many schematic di-<lb/>agrams. Bertin considered a range of simple glyphs in the context of <lb/>geo-information visualization [7]. Ward surveyed the use of glyphs <lb/>in visualization, and discussed a number of bias issues, design ap-<lb/>proaches, and layout options [58]. Ropinksi et al. conducted a survey <lb/>on glyph-based techniques in medical visualizations [48]. In visual-<lb/>ization, a number of interesting glyph designs have been presented <lb/>with noticeable impact on a large range of applications (e.g., medicine <lb/>[25], software [13], text [47], and scientific computation [62]). Fur-<lb/>thermore, Ribarsky et al. developed an editing system, Glyphmaker <lb/>[45], to assist the process of designing glyphs. Post et al. proposed <lb/>a language, Icon Modeling Language, for creating glyphs and glyph-<lb/>style contours [42]. <lb/>There have been some recent efforts to use glyph-based visualiza-<lb/>tion in biological sciences. One noticeable attempt is the Systems Bi-<lb/>ology Graphical Notation (SBGN) [28]. The design of SBGN makes <lb/>use of the notional representations of UML with some modifications to <lb/>describe the biological entities and their interactions within a biolog-<lb/>ical system. GenoCAD [11] provides a grammar-based language for <lb/>representing and searching DNA sequences and for building genetic <lb/>constructs from DNA sequences, facilitating the use of conventional <lb/>link diagrams. Both systems rely heavily on text labels. In handling <lb/>a large collection of workflows, they exhibit a few shortcomings, such <lb/>as inefficiency in using display space and ineffectiveness in supporting <lb/>some visualization tasks, such as comparisons and novelty or anoma-<lb/>lies detection in workflows. <lb/>In the literature, several authors encouraged glyph designers to con-<lb/>sider visual perception when constructing glyphs [58, 23]. Others <lb/>examined the design space of icons, which normally encode less in-<lb/>formation than glyphs (e.g., [21, 29]). There were perceptual studies <lb/>showing the merits of icons over text labels (e.g., [34, 41]), as well <lb/>as those showing the contrary (e.g., [60]). Building on such discus-<lb/>sions, this work aims to address a methodological need for a system-<lb/>atic approach to glyph design for applications where large collections <lb/>of concepts need to be visually encoded using glyphs. <lb/> 2.2 Workflow Visualization <lb/> The need for workflow visualization is pervasive across many different <lb/>domains. For example, in business and management the Gantt chart is <lb/>a form of text based workflow visualization, while BPMN (Business <lb/>Process Model and Notation) and EPC (Event-driven Process Chain) <lb/>make use of icons to enrich text labels. In engineering disciplines, var-<lb/>ious schematic diagrams, such as UML (Unified Modeling Language), <lb/>Petri-net and circuit diagrams, are used to convey data flow and pro-<lb/>cess interaction. <lb/>In this work, we consider workflows used to describe biological <lb/>experiments. This class of workflow visualization renders the pro-<lb/>cesses enacted on biological materials in an experiment (e.g., removal <lb/>of blood sample from patient). There has been little effort to develop <lb/>tools that address the domain-specific needs. Scientists usually use <lb/>generic text-based graph drawing tools such as GraphViz [3]. <lb/>One related aspect is pathway visualization, which is concerned <lb/>with the rendering of cellular biological processes. An array of path-<lb/>way visualization tools have been developed, some of which incorpo-<lb/>rate glyphs. For example, VANTED [22] overlays glyphs representing <lb/>gene expression, enzyme and metabolite profile data on top of path-<lb/>way diagrams from KEGG [37]. GENeVis [9], which also employs <lb/>glyphs to represent multivariate data, is a comprehensive visualization <lb/>toolkit for exploration of pathways in conjunction with temporal data. <lb/>GenoCAD has at its core a workflow generation system and relies on <lb/>their glyph library for rendering of the different biological processes <lb/>within a cell. SBGN-ED [14], is an add-on for the VANTED software <lb/>and performs pathway creation using the aforementioned SBGN [28] <lb/>visual language. <lb/> 3 MOTIVATION AND OVERVIEW <lb/> The advent of massively parallel techniques such as DNA microar-<lb/>ray, mass-spectrometry based proteomics and metabolomics and next <lb/>generation sequencing enables molecular biologists to collect, process <lb/>and manipulate biological signals on a new scale. Big data in biology <lb/>is a reality. There has been serious effort in biology to ensure qual-<lb/>ity of experimental records by providing data archiving infrastructure <lb/>and defining standards for adequate annotation and sufficient details <lb/>for recapitulation of results. A number of molecular biology signature <lb/>databases have been or are being established to cover the main molec-<lb/>ular dimensions: transcript, protein and metabolites. The captured <lb/>metadata mostly revolves around a similar configuration where sets of <lb/>samples corresponding to different conditions are processed, measure-<lb/>ments produced and analysis performed, delivering data that needs to <lb/>be handled and interpreted. While the availability of such metadata <lb/>facilitates comparison across datasets and enables meta-analysis, pro-<lb/>viding means to serve an overview of experimental design can assist <lb/>analysts and data managers alike, from data selection according to rel-<lb/>evancy, to error detection such as imbalances, irregularities or incon-<lb/>sistencies in records. <lb/> Task Analysis. In the context of meta-databases for experimental <lb/>records, there are two main groups of users. The majority of users are <lb/>those who create data for their biological experiments or retrieve data <lb/> Biological data <lb/>repositories <lb/>Data Capture &amp; <lb/>Processing <lb/>Formulating <lb/>Taxonomy <lb/>Visual <lb/>Mapping <lb/>Metaphoric <lb/>Abstraction &amp; <lb/>Association <lb/>Glyph <lb/>set <lb/>Implementing <lb/>Glyph-based <lb/>visualization <lb/> Glyph design <lb/> Fig. 2. A systematic process for creating glyph based representations. <lb/> relevant to their scientific interests. Their tasks include: (a) entering <lb/>and editing their own experimental records; (b) transforming workflow <lb/>records to schematic diagrams for comparison, external memorization, <lb/>publication and education; (c) uploading and downloading datasets; <lb/>(d) querying and searching for relevant experiments; (e) understanding <lb/>workflows of existing experimental designs; (f) identifying similarity <lb/>and difference between workflows for a common task; (g) understand <lb/>pooling events and sample relations (derivation). <lb/>The second group of users are curators who manage data archives. <lb/>As biology or bioinformatics scientists themselves, they perform the <lb/>above-mentioned tasks (d)-(g) frequently, and (b)-(c) occasionally. In <lb/>addition, they also carry tasks for: (h) checking syntactic correctness <lb/>of submitted workflows; (i) checking semantic correctness of submit-<lb/>ted workflows which usually involves reading the associated publica-<lb/>tions then comparing the submitted workflows with those described in <lb/>the publications; (j) interacting with authors of submitted workflows <lb/>to clarify any inconsistency and misunderstanding; (k) making appro-<lb/>priate corrections in submitted records where necessary; (l) augment-<lb/>ing with appropriate annotation based on additional information found <lb/>in the associated publications; (m) providing authors with submission <lb/>feedback. (n) forming an up-to-date overview about the experiments <lb/>in the data archives, and maintaining an insight about the provenance <lb/>of the archives; (n) analyzing the grouping, replication, distribution <lb/>and trend of experiments; (o) analyzing ambiguities, errors and un-<lb/>certainty in experimental recording, and identifying the need to enrich <lb/>and refine the relevant standards for ontology, labelling and annota-<lb/>tion. (p) providing tools to assist users in creating meta-data from raw <lb/>data. <lb/>It is not difficult to observe that effective workflow visualization can <lb/>significantly improve users&apos; capability in performing tasks b, e, f, g, h, <lb/>i, j, l, n, o and p. <lb/>While it is necessary to evolve a glyph-based design for workflow <lb/>visualization over a period, it is also important not to make the first <lb/>step in an ad hoc manner. Such a process does not scale well with <lb/>the requirements of the application concerned where a large number <lb/>of concepts are to be encoded using glyphs. We thus adopt a new sys-<lb/>tematic process for glyph design by exploring the parallel between the <lb/>hierarchy of concept categorization and the ordering of discriminative <lb/>capacity of visual channels. Fig. 2 depicts this process. <lb/> Data Capture and Processing. We first retrieved workflow <lb/>metadata from a biological repository (content of the ArrayExpress <lb/>archive), through use of a multi-threaded harvesting operation. All ex-<lb/>perimental workflows were then converted using a MAGE-Tab to ISA-<lb/>Tab converter, the latter format being more general than the former and <lb/>can be used to carry metadata payloads for many types of experiments, <lb/>making the data processing program more &quot; future-proof &quot; . <lb/>From the 21,000 ISA-Tab files, we extracted all names of protocols <lb/>(processes) and biological materials, chemical materials, devices and <lb/>data used in annotation. We also computed the occurrence of each <lb/>material and process found in the entire set of ISA-Tab files, which <lb/>have been used as one of the metrics in the next stage (see Section 5 <lb/>for details). This step results in 61 process names and 3492 names <lb/>of inputs and outputs (e.g., biological and chemical materials, device <lb/>measurements and data). <lb/> Taxonomy Formulation. Since a taxonomy for such a large col-<lb/>lection of terms is absent, we, for starters, established a set of cat-<lb/>egorization schemes with the help of domain experts. For example, <lb/>one of the schemes for categorizing processes may be based on dif-<lb/>ferent biological inputs to a process (e.g., molecule, cell, organism, <lb/>etc.). Another scheme may be based on processing methods (e.g., per-<lb/>turbation, combination, etc.). We computed the quality measures of <lb/>each scheme based a set of generic metrics (see Section 4) then cre-<lb/>ated a taxonomic tree by recursively selecting the best categorization <lb/>scheme based on the quality measures. We finalized the organization <lb/>of the taxonomy by allowing domain experts (2 co-authors) to make <lb/>adjustments according to domain-specific conventions. All leaf nodes <lb/>of the resulting taxonomy tree are names extracted from the workflow <lb/>metadata. All non-leaf nodes represent a categorization scheme. <lb/> Glyph Design. First, we established an ordering of commonly-<lb/>used visual channels based on the literature focused on perception and <lb/>visualization (see Section 5). This allows us to systematically compare <lb/>the order of categorization schemes in the taxonomy with the order of <lb/>different visual channels. Ideally, schemes at the upper level of the <lb/>tree can be mapped to visual channels which are more prominent to <lb/>our visual system. <lb/>We then proceeded to the glyph design process involving two inter-<lb/>twined sub-processes for visual mapping and metaphoric abstrac-<lb/>tion and association. We proposed various options of visual chan-<lb/>nels for each categorization scheme featured in the taxonomic tree. <lb/>We considered the merits of these visual channels and identify po-<lb/>tential conflicts with the visual channels that have been assigned to <lb/>other schemes. With the direct help from domain experts, we tried to <lb/>identify a metaphoric abstraction or association for each design option <lb/>proposed. We evaluated and recorded the intuitiveness and suitability <lb/>of the abstraction and metaphor association. <lb/>Informed by the results the two sub-processes, we finalized a glyph <lb/>set by selecting a design option for each scheme, while maintain-<lb/>ing the order of discriminative capacity of visual channels, minimiz-<lb/>ing conflicts between different channels, and maximizing the use of <lb/>metaphoric abstraction and association. <lb/> Implementation of Glyph-based Visualization. We then inte-<lb/>grated the glyph set with a layout algorithm to form a prototype sys-<lb/>tem for workflow visualization (see Section 6). For demonstration <lb/>purposes, we tested the workflow visualization in conjunction with <lb/>ISAcreator, a popular domain agnostic biological experiment meta-<lb/>data capture tool. <lb/> 4 TAXONOMY GENERATION <lb/> Given a large collection of concepts, we should ideally make use of a <lb/>standard taxonomy, where non-leaf nodes represent different catego-<lb/>rization schemes and each scheme provides subclasses that lead to dif-<lb/>ferent sub-trees. In many circumstances, however, there is no agreed <lb/>taxonomic tree as establishing a standard categorization requires non-<lb/>trivial scientific effort that often spans over a few decades. <lb/>The algorithm described below is not intended to establish a <lb/>semantic-rich taxonomic tree for classifying concepts. It is designed <lb/>purely for addressing the needs for ordering various categorization <lb/>schemes (when there is no such an agreed order) to aid glyph design, <lb/>and for devising a useful tree data structure in implementing the map-<lb/>ping between concepts and glyphs in workflow visualization. <lb/>Hence, the criteria used for structuring the tree are based on usage <lb/>of the concepts and the structural quality of the tree to be constructed. <lb/>Taxonomy is a long standing concept that can be traced back to <lb/>3000BC [32]. Automatic taxonomy generation has been an active field <lb/>in computer science and computational biology with existing work <lb/>largely focusing on clustering algorithms (e.g., [27]). Many such al-<lb/>gorithms assume the availability of similarity measures for ordering <lb/>entities rather than relying on the existence of individual categoriza-<lb/>tion schemes. In these algorithms, there is usually no attempt towards <lb/>application of a metric for creating meaningful non-leaf nodes in the <lb/>resulting tree. In this work, it is essential to keep each categorization <lb/>scheme as a non-leaf node unless it is redundant. <lb/> 4.1 Ordering Classification Schemes <lb/> Let X = {x  1  , x  2  , . . . , x n  } be a set of concepts to be classified. In our <lb/>application, this is the set of all valid names of biological processes <lb/>and IOs (inputs and outputs) in the database. Each concept x i  is asso-<lb/>ciated with a scalar value,  µ  i  ∈ [0, 1], indicating its frequency of usage <lb/>in relation to the total occurrence of all concepts in the database. There <lb/>are a number of categorization schemes, S = {S  1  , S  2  , . . . , S m  }. Each <lb/>scheme, S k  divides concepts into several classes, c k <lb/> 1  , c k <lb/> 2  , . . . , c k <lb/>l k <lb/> . The <lb/> relationship between the concept set X and different classification <lb/>schemes can thus be represented by a Boolean matrix, A, where each <lb/>element  α[i,  j, k] = 1 if concept x i  belongs to the j th  class of scheme <lb/> S k  ; otherwise  α[i,  j, k] = 0. In the context of feature-based categoriza-<lb/>tion, one can also view each scheme S k  as a feature, and each class <lb/>under S k  as a particular type of this feature. Without losing general-<lb/>ity, we assume that the classes under the same S k  are disjoint. It is <lb/>also possible that a concept does not possess the k th  feature, and hence <lb/>does not belong to any class under S k  . <lb/>Given the above categorical information about the concept set X , <lb/>one can choose a categorization scheme S k  ∈ S , which will divide X <lb/> into a number of disjoint subsets corresponding to classes c k <lb/> 1  , c k <lb/> 2  , . . . , c k <lb/>l k <lb/> and c k <lb/> 0 . The subset c k <lb/> 0 contains those concepts which S k  is unable <lb/>to classify. The partitioning process can be repeated recursively by <lb/>applying one of the remaining categorization schemes in S to each <lb/>subset. This results in a hierarchical categorization tree, which defines <lb/>a taxonomy for the concepts set X . <lb/>The ordering of the schemes in S thus determines the taxonomic <lb/>structure of X . It is not difficult to anticipate that many criteria can be <lb/>used to determine the ordering for a given concept set. Some criteria <lb/>will no doubt encode application-specific semantics, and some may be <lb/>subjective or debatable. However, there are also some common-sense <lb/>criteria that are generic to most applications. These include: <lb/> Coverage. The number of concepts that can be classified by scheme <lb/> S k  is a capacity measure of S k  . The more concepts that S k  can classify <lb/>(i.e., the fewer in c k <lb/> 0 ), the better. The measure, which is normalized by <lb/>the set size | X |= n, can be defined as: <lb/> M  1  (S  k  ) = <lb/> ∑ <lb/> n <lb/>i=1  max 1≤ j≤l k  (α  i, j,k  ) <lb/> n <lb/> . <lb/> (1) <lb/> Potential Usage. A categorization scheme that is higher up in the <lb/>taxonomical tree is expected to be used more often in the application <lb/>concerned. The occurrence frequencies of concepts,  µ  i  , enable us to <lb/>estimate the potential usage of a classification scheme as follows: <lb/> M  2  (S  k  ) = <lb/> ∑ <lb/> n <lb/>i=1  µ  i  max 1≤ j≤l k  (α[i, j, k]) <lb/> ∑ <lb/> n <lb/>i=1  µ  i <lb/> . <lb/> (2) <lb/> Subtree Balance. Having a balanced node distribution in a tree is a <lb/>desirable property of a tree structure. It prevents a tree from having an <lb/>excessive height, which corresponds to the need for more visual chan-<lb/>nels. Let l k  denote the number of subclasses in categorization scheme <lb/> S k  ,  τ  j  be the number of concepts in each subclass c k <lb/>j  , j = 1, 2, . . . , l k  and <lb/> σ τ  and ¯ <lb/> τ  be the standard deviation and mean respectively of  τ  1  , . . . ,  τ  l k  . <lb/>We can measure the level of balance as follows: <lb/> M  3  (S  k  ) = <lb/>  <lb/>  <lb/> <lb/> <lb/> <lb/> 0 <lb/> ∑ <lb/> l k <lb/> i=1  τ  l i  = 0 <lb/>1 <lb/> σ τ  &lt;  ε(ε  &gt; 0) <lb/> P( ¯ <lb/> τ  ± 1 | N  ¯ <lb/> τ,σ τ  ) ¯ <lb/> τ  &gt; 0 &amp;  σ τ  &gt;  ε <lb/> (3) <lb/>where P is the probability that a value within [ ¯ <lb/> τ  − 1, ¯ <lb/> τ  + 1] falls under <lb/>the curve given by the normal distribution N with ( ¯ <lb/> τ, σ τ  ) [40]. There <lb/>are two special cases. When all values of  τ  j  are 0, S k  cannot classify <lb/>any concept; hence the metric returns a zero score. When  σ τ  = 0, <lb/>the subtree is totally balanced; hence the metric returns one. As  σ τ <lb/> approaches zero, the function P becomes numerically unstable, we use <lb/>a cut-off value  ε  to prevent this. In this work, we set  ε  = 0.00001. The <lb/>normal distribution is preferred over a  χ-test,  as  χ  may not be reliable <lb/>when l k  is a small number. <lb/> Number of Subclasses. All visual channels used in glyphs have <lb/>limited discriminative capacity. A higher number of subclasses in a <lb/>scheme would require visual encoding to have more codewords (e.g., <lb/>more colors or more shape types), which will increase users&apos; cognitive <lb/>load in learning, remembering, and recognizing the codewords. It is <lb/>thus more desirable to have a smaller number of subclasses, except <lb/>that a categorization scheme with fewer than 2 sub-classes is useless. <lb/>Let  η  ⊤  be an up-limit for the number of codewords, which is set to <lb/>10 in this work. We introduce the following metric to measure the <lb/>discriminative capacity of a scheme: <lb/> M  4  (S  k  ) = <lb/>  <lb/> <lb/> <lb/> <lb/> <lb/> 0 <lb/> η  k  &lt; 2 <lb/> η <lb/> ⊤ −η  k  +2 <lb/> η  ⊤ <lb/> 2 ≤  η  k  ≤  η  ⊤ <lb/> 1 <lb/> η  ⊤ <lb/> η  k  &gt;  η  ⊤ <lb/> (4) <lb/>Although the above four metrics have been normalized to ensure <lb/>their functional values within the [0, 1] domain, the distribution of the <lb/>values for different schemes can still be rather application-specific and <lb/>may vary substantially between different metrics. This may lead to <lb/>inconsistency in combining these metrics. <lb/>We thus provide an optional linearization filter for these metrics by <lb/>mapping the values obtained using a each metric M i  into fractional <lb/>ranking numbers, which are then normalized into the [0, 1] domain <lb/>with 1 being the best and 0 the worst. For example, consider a set of <lb/>six schemes with metric values: <lb/> (S  1  , 0.5), (S  2  , 0.3), (S  3  , 0.54), (S  4  , 0.8), (S  5  , 0.85), (S  6  , 0.6). <lb/>We first sort the set: <lb/> (S  2  , 0.3), (S  1  , 0.5), (S  3  , 0.54), (S  6  , 0.6), (S  4  , 0.8), (S  5  , 0.85) <lb/>We then obtain the normalized ranking values via the distance for or-<lb/>dinal variables function  σ  = <lb/> r−1 <lb/>R−1  where R is the top rank and r is the <lb/>rank position for each schema. <lb/> (S  2  , 0), (S  1  , <lb/> 1 <lb/>5 <lb/> ), (S  3  , <lb/> 2 <lb/>5 <lb/> ), (S  6  , <lb/> 3 <lb/>5 <lb/> ), (S  4  , <lb/> 4 <lb/>5 <lb/> ), (S  5  , <lb/> 5 <lb/>5 <lb/> ). <lb/> We denote this filter as a function R(S k  , M i  , S ). Using the above set <lb/>of metrics in conjunction with the filter R, we can derive a combined <lb/>metric as <lb/> M(S k  ) = <lb/> ∑ <lb/> 4 <lb/>1  ω  t R(S k  , M t  (S  k  ), S ) <lb/> ∑ <lb/> 4 <lb/>1  ω  t <lb/> . <lb/> where  ω  t  ,t = 1, 2, 3, 4 are user-adjustable weights for the four individ-<lb/>ual metrics. Similar to weights in clustering algorithms, these weights <lb/>need to be used with care as they introduce additional semantics into <lb/>the ordering algorithm. <lb/>Equipped with the combined metric M, the algorithm for establish-<lb/>ing an order of different schemes in S can be described as follows: <lb/> proc select(S , X ) ≡ <lb/> S BEST  := null; m BEST  := 0; <lb/> for S ∈ S do <lb/> m := M(S); <lb/> if m &gt; m BEST <lb/> S BEST  := S; m BEST  := m; <lb/>out put(S BEST  ); <lb/> remove S BEST  from S ; <lb/>split X into subsetsX 1  , X  2  , . . ., based on S BEST  ; <lb/> if | subsets |≤ 1 <lb/> return; <lb/> fi <lb/>for each subsetX  k  do <lb/> select(S , X  i  ); <lb/> od <lb/>fi <lb/>od. <lb/> 4.2 Application to the Biological Case Study <lb/> The biological community has built over the years a comprehensive <lb/>collection of resources to archive experimental data. As molecular <lb/>biology became a more data intensive field with the advent of DNA <lb/>microarrays, came the need to store not only measurements but also <lb/>ancillary annotation describing experimental conditions and set up, <lb/>thus ensuring a metadata core always shipped with the data set. The <lb/> Table 1. A fragment of the input document passed to the taxonomy gen-<lb/>eration algorithm. Schemes are grouped by common names preceding <lb/>the semi-colon, e.g. S1:On Material refers to schema 1 and On Material <lb/> is the classification. <lb/> Process Name <lb/>Occurrences S1:Material S1:Data . . . <lb/>S6:in vitro S6:in vivo S6:in silico <lb/> labeling <lb/> 390811 <lb/> 1 <lb/>. . . <lb/>1 <lb/> nucleic acid extr. <lb/> 350267 <lb/>1 <lb/>. . . <lb/>1 <lb/> hybridization <lb/> 345671 <lb/>1 <lb/>. . . <lb/>1 <lb/> feature extr. <lb/> 267044 <lb/>1 <lb/>. . . <lb/>1 <lb/> bioassay data trans. <lb/> 176347 <lb/>1 <lb/>. . . <lb/>1 <lb/> grow <lb/> 116194 <lb/>1 <lb/>. . . <lb/>1 <lb/> pool <lb/> 68004 <lb/>1 <lb/>. . . <lb/>1 <lb/>. . . <lb/>. . . <lb/>. . . <lb/>. . . <lb/>. . . <lb/>. . . <lb/>. . . <lb/>. . . <lb/> sizes of microarray databases (GEO, AE) constitute prime resources <lb/>for evaluating and testing our approach [2, 1]. The content of Ar-<lb/>rayExpress was therefore accessed obtaining data via parallel calls, <lb/>converting 21000 experiments and associated experimental metadata <lb/>to ISA-Tab[46, 50]. This step provided a harmonized format in which <lb/>to represent not just transcriptomic data, but also genomic, proteomic, <lb/>metabolomic and other classical experiment types. <lb/>Given the data sets, the code analyzes the content of these direc-<lb/>tories to determine the processes and IOs which exist within the ex-<lb/>periments, and the number of times they occur. The analysis revealed <lb/>61 processes (a small number resulting from the homogeneity of the <lb/>database where analysis techniques are targeted primarily towards <lb/>DNA microarrays) with 1,845,089 occurrences and 8,223 properties <lb/>of the sample of which 3492 were deemed to be IOs with 486,353 <lb/>occurrences. <lb/>Several distinct, empirical but meaningful, categorizations were de-<lb/>vised encompassing a number of facets defining the properties of the <lb/>experimental process, either in terms of its participants or in terms of <lb/>key process properties. Classifications, based on features such as the <lb/>nature of process participants, the granularity scale, the nature of ex-<lb/>periments and common types a treatments applied in biological experi-<lb/>ments were developed. Some classifications were somewhat informed <lb/>by the overall assumptions ISA model relies upon, where nodes can be <lb/>either material or data files and where edges are processes acting upon <lb/>those nodes. Others resulted from applying a small number of axioms <lb/>discovered through consultations with domain experts. There were 6 <lb/>classification schemes in all with a total of 23 sub-classifications, these <lb/>are detailed in figure 3. Table 4.2 shows a snapshot of the input file <lb/>used in the classification algorithm. <lb/>The schemes are not tied to any existing taxonomic tree, may not <lb/>be orthogonal and/or may be redundant with respect to others. The <lb/>development of the classifications was not the result of application of <lb/>any knowledge engineering methods and there is no ontological com-<lb/>mitment, although in theory the classification names used could be <lb/>derived from an ontological framework. The reason for not relying <lb/>an ontology in the first place was risk mitigation, where use would al-<lb/>most certainly result in an unbalanced tree as occurrence counts for the <lb/>terms would not be considered, resulting in creation of many glyphs <lb/>that would never be used. <lb/>The creation of the tree shown in Fig. 3 was a largely iterative <lb/>quest with continuous involvement of domain experts checking to en-<lb/>sure that the classifications assigned were meaningful. From early <lb/>versions of the classification matrix creation, classifications were re-<lb/>moved, added or merged in consultation with those who knew the data <lb/>domain. For example, in S2 there were sub-classifications in Genetic <lb/>Modification &amp; Labeling which are types of Material Combination. <lb/> Therefore, these sub-classifications were removed since it would be <lb/>technically and semantically incorrect to keep them. These early in-<lb/>teractions emphasized the importance of having domain experts in the <lb/>loop, otherwise classifications and subsequent glyphs would not be as <lb/>well created as they could be. <lb/>The algorithm managed to correctly place the classifications where <lb/>they were expected (checks were made by hand to ensure that the al-<lb/>gorithm performed well). Schema S6 (in vitro, in silico and in vivo) <lb/> was the best top level classification due to its overall fitness metric of <lb/>3.08 with individual metrics found to be: M1 = 1.0; M2 = 1.0; M3 = <lb/>0.9; and M4 = 0.18. S6 was closely followed by S1 (on material and on <lb/> C1 on material <lb/> C2 on data <lb/> C1 data acquisition <lb/> C2 data preprocessing <lb/> C3 data analysis <lb/> C1 material perturbation <lb/> C2 material combination <lb/> C3 material amplification <lb/> C4 material separation <lb/> C5 material collection <lb/> C1 behaviourally induced perturbation <lb/> C2 physically induced perturbation <lb/> C3 material induced perturbation <lb/> C1 input molecular part <lb/> C2 input cellular component <lb/> C3 input cell <lb/> C4 input tissue <lb/> C5 input organ <lb/> C6 input organism <lb/> C7 input population <lb/> C1 in vitro <lb/> C2 in silico <lb/> C3 in vivo <lb/> Schemes &amp; classifications <lb/> C1 biological <lb/> C2 device <lb/> C3 chemical <lb/> C4 data <lb/> C1 inputs and outputs <lb/> C2 processes <lb/> Fig. 3. The classification algorithm arranged the classification schemes <lb/>in the above order. <lb/> data), however after the top level separation, S1 became redundant as <lb/>a result of the top level implicitly making a split on data (in silico) and <lb/>materials (in vitro and in vivo). The algorithm successfully detected <lb/>this redundancy; hence S1 is absent from Fig. 3. <lb/>Although the algorithm performed as expected, a possible criticism <lb/>of the algorithm could be highlighted in the placement of S5 below <lb/> S4. S5 could have been placed above S4 in line with the observation <lb/>that, for the majority of cases, S5 was selected over S4. The reason S5 <lb/> wasn&apos;t used to sub-classify C1 of S4 is due to its number of classifi-<lb/>cations (7) being greater than that of S4 (3), therefore S4 was selected <lb/>primarily on this metric even though the sub-tree balance of S5 (0.8) <lb/>was slightly better than that of S4 (0.68). To modify this behavior, it <lb/>was necessary to involve domain experts in refining the tree based on <lb/>their domain-specific knowledge and case-specific requirements. <lb/> 5 VISUAL ENCODING <lb/>5.1 Perceptual Guidance <lb/> A glyph is a small visual object composed of a number of visual chan-<lb/>nels which can be used independently as well as constructively to de-<lb/>pict attributes of a data record. Glyphs are of a type of visual signs that <lb/>can make use of visual features of other types of signs, such as icons, <lb/>indices and symbols. <lb/>Although there are several books on sign design (e.g., [6, 4]), they <lb/>focus on signage in public space, and offer empirical guidance on a <lb/>large number of issues including standardization, size, location, illu-<lb/>mination and so on. Many of these issues are not quite relevant to the <lb/>need for visualizing the workflows of biological experiments. Here, <lb/>we draw our design principles mainly from findings in perception, es-<lb/>pecially in the area of visual search [54, 43]. <lb/>While the extensive use of signs, icons and pictograms in everyday <lb/>life reflects their usefulness and effectiveness, several perceptual stud-<lb/>ies also directly or indirectly confirmed their perceptual and cognitive <lb/>merits. For example, Franks and Bransford&apos;s study on transformation <lb/>of prototypes [16] suggested that humans can learn to recognize glyphs <lb/>by rules consciously as well as unconsciously. The presence of iconic <lb/>memory [53] may facilitate rapid comparison between glyphs in the <lb/>same display, whereas it is less so for texts. <lb/> Guideline on Semantic Relevance. Bertin [7] classified visual <lb/>channels (which he referred to as retinal variables) into two categories, <lb/>planar (location) and retinal (size, color, shape, orientation, texture <lb/>and brightness). Bertin proposed four semantic criteria for determin-<lb/> Table 2. Perceptual strength of different visual channels based on levels of organization studied by Bertin[7] and Green[17], &apos;popout&apos; effect studied <lb/>extensively in psychology [61, 15, 31, 7, 17, 63, 55, 38, 39], and hierarchy effect studied by Navon [35] and Love [30]. The summary strength of <lb/>each channel is estimated and it should be considered in conjunction with application-specific conventions and metaphors. <lb/> Visual <lb/> Levels of Organization <lb/>Popout Hierarchy Summary <lb/>Convention <lb/>Regions <lb/>Channels <lb/>Associative Selective Ordered Quantitative Effect <lb/>Effect <lb/>Strength <lb/>&amp; Metaphor <lb/> a) Main <lb/>1. Color <lb/>Yes <lb/>Yes <lb/>Yes <lb/>***** <lb/>Strong <lb/>***** <lb/>application <lb/>2. Size <lb/>Yes <lb/>Yes <lb/>Yes <lb/>*** <lb/>**** <lb/>specific <lb/>3. Shape <lb/>Yes <lb/>Yes <lb/>*** <lb/>*** <lb/>4. Orientation <lb/>Yes <lb/>Yes <lb/>*** <lb/>*** <lb/>5.Texture <lb/>Yes <lb/>Yes <lb/>Yes <lb/>** <lb/>** <lb/>b) Supplementary 6-10 (same as 1-5) <lb/>Medium <lb/>11. Planar <lb/>Yes <lb/>Yes <lb/>Yes <lb/>*** <lb/>*** <lb/>c) Interior <lb/>Contains (a+b)) <lb/>Low <lb/> ing the suitability of different channels in representing certain types <lb/>of information. These semantic criteria are: associative, selective, or-<lb/>dered and quantitative. These criteria are important guidelines, though <lb/>there has been disagreement in the literature as to how individual vi-<lb/>sual channels are judged. For example, Bertin considered shape as a <lb/>non-selective variable. Research has shown that shapes such as filled <lb/>rectangles, circles and triangles do not allow the human visual sys-<lb/>tem to identify one shape from another effectively in a rapid action <lb/>when they form some global structures [30, 35], (they have poor &quot; pop-<lb/>out &quot; effect). However, the omission of all shapes as a selective visual <lb/>channel has been challenged, for example, by [56, 57, 17], who show <lb/>practice and familiarity can support selectivity with almost any shape. <lb/> Guideline on Channel Composition. As a glyph is likely to fea-<lb/>ture a number of visual channels, the constructive composition may <lb/>affect how individual channels are perceived. A rich collection of lit-<lb/>erature on integral and separable dimensions shows that the combined <lb/>dissimilarity of closely integrated visual channels exhibits Euclidean <lb/>distance <lb/> d  2 <lb/> a  + d  2 <lb/> b  [26, 18], whereas that of separable visual chan-<lb/>nels exhibits city-block distance d a  + d b  [10, 51]. The latter is more <lb/>cost-effective than the former in rule-based encoding of multi-faceted <lb/>concepts, therefore effective glyph design should encompass a non-<lb/>conflicting set of separable retinal variables. <lb/> Guideline on Pop-out Effects. Many classic studies in percep-<lb/>tion also established the &quot; power &quot; of different visual channels in terms <lb/>of pop-out effect (pre-attentive search), and fixation (during attentive <lb/>search)[19]. The pop-out effect is one which allows identification of <lb/>a target within a few nanoseconds of initial exposure to the visual <lb/>search space. A result of several milestone studies focusing on ob-<lb/>served response times, the ordering of the four commonly used visual <lb/>channels follows the consensus: color ≺ size ≺ shape ≺ orientation <lb/>(e.g.,[61, 44, 48]). The symbol ≺ reads as precedes. However, the <lb/>strength of color over the other three channels is generally much more <lb/>noticeable. <lb/> Guideline on Visual Hierarchy. Visual hierarchy, with which the <lb/>environment and objects around us are arranged is a well documented <lb/>theoretical framework [38, 35, 30, 24, 5]. However, the literature con-<lb/>tains a debate over the ways in which the visual system traverses this <lb/>hierarchy. There are four possible ways: top-down (also called global <lb/>processing) [35]; bottom-up (also called local processing); middle-out <lb/>[24]; and salient features (e.g., edges, points, colors) [49]. Because <lb/>glyphs are relatively small in comparison with a whole visualization, <lb/>we consider at such a &quot; localized level &quot; , the top-down and salient fea-<lb/>tures may play more significant roles. The top-down assumption sug-<lb/>gests that when consider a glyph in isolation, its global feature will <lb/>affect visual search more than its local features. Salient features are <lb/>partly addressed by the pop-out effects. <lb/>Based on the above-mentioned perceptual guidance, we considered <lb/>a generic glyph design template for this work as shown in Fig. 4(a). <lb/>The template divides a glyph into three regions, namely main body, <lb/>exterior and interior. In practice, each region can be divided into 2 <lb/>or more sub-regions (e.g., a twin body glyph or 4 exterior sections), <lb/>it is convenient to consider the three regions in abstraction. The sep-<lb/>aration of these regions facilitates the basic separation of visual chan-<lb/>nels based on the composition guideline, while allowing us to consider <lb/>them individually according to the hierarchy guideline. <lb/> supplementary <lb/> main body <lb/>interior <lb/>process <lb/>S2 &amp; S4 <lb/>S6 <lb/>S5 <lb/>S3 <lb/>unused <lb/> Fig. 4. (a) The glyph template with a main body, an interior region and <lb/>an exterior region (consisting of 4 sections). (b) Our final design makes <lb/>use of the main body and interior region. The exterior is reserved for <lb/>future extension. <lb/> In theory, the exterior and interior regions may also be divided into <lb/>sub-regions in a recursive fashion though in practice this is tightly con-<lb/>strained or discouraged by the very limited display resolution typically <lb/>available for glyphs. Similar to the design convention for icons, pic-<lb/>tograms are normally featured in the interior region. The exterior re-<lb/>gion may be further divided in four sections (top, bottom, left and <lb/>right). If glyphs will be connected to form a network or graph (as in <lb/>this work), the use of these four sections has to take into account the <lb/>possible incoming and outgoing connections. <lb/>Table 2 summarizes relative merits of some of the most commonly-<lb/>used visual channels in different regions according to Bertin&apos;s cate-<lb/>gorization, pop-out effects and hierarchy effects. We estimated the <lb/>overall discriminating capacity of each channel by using a summary <lb/>rating in the penultimate column. We also recognized the importance <lb/>of the conventions and metaphors in an application. We will discuss <lb/>visual metaphors further in Section 5.2. We added the last column to <lb/>highlight the necessity to consider these in a design process. <lb/>It is difficult to establish an accurate ranking order of different vi-<lb/>sual channels by taking all perceptual effects into account in a quan-<lb/>titative manner. The state of the art in perception research is yet to <lb/>provide all evidence needed for a full and conclusive analysis. Nev-<lb/>ertheless, Table 2 can serve a qualitative guidance to glyph designs in <lb/>this work, providing an ordering of visual channels in parallel with the <lb/>ordering of categorization schemes discussed in Section 4. <lb/> 5.2 Mapping Taxonomy to Visual Channels <lb/> For each scheme in the taxonomic tree as shown in Fig. 3, we propose <lb/>a number of design options. Fig. 5 shows some examples of the pro-<lb/>posed designs. For example, the first column shows the use of colors <lb/>to encode the classes of a categorization scheme. The second column <lb/>shows the use abstract shapes. Some options convey an abstraction <lb/>from pictorial representations of classes, and in other cases, we try <lb/>to establish a metaphoric association between a visual channel and a <lb/>biological categorization. <lb/>Metaphoric visual representations enable domain-specific encoding <lb/>using &quot; natural mapping &quot; [52, 36]. This natural mapping can make it <lb/>easier for users to infer meaning from the glyph with less effort re-<lb/>quired to learn and remember them [33]. A recent study showed that <lb/>visual metaphors can aid memorization of the information depicted in <lb/>a visualization [8]. However, the same study also showed that visually <lb/>realistic metaphors (those with a lot of detail) may have a negative <lb/> Molecule. <lb/> Cellular <lb/>Part <lb/>Cell <lb/>Tissue <lb/>Organ <lb/>Organism <lb/>Population <lb/>Data <lb/>Collection <lb/>Data <lb/>Processing <lb/>Data <lb/>Analysis <lb/>Material <lb/>induced <lb/>pertubation. <lb/>Behaviourally <lb/>induced <lb/>pertubation. <lb/>Physically <lb/>induced <lb/>pertubation. <lb/>In Vitro <lb/>In Vivo <lb/>In Silico <lb/>Material <lb/>perturbation <lb/>Material <lb/>separation <lb/>Material <lb/>amplification <lb/>Material <lb/>combination <lb/>Material <lb/>collection <lb/> design option 7 <lb/>design option 6 <lb/>design option 5 <lb/>design option 4 <lb/>design option 3 <lb/>design option 1 <lb/>design option 2 <lb/> Inputs and <lb/>Outputs <lb/>Process <lb/>Device <lb/>Chemical <lb/>Data <lb/>Biological <lb/> Fig. 5. Experimenting with visual channels: an overview of the various <lb/>design options available for use in representing the different classifica-<lb/>tions. Most schemes for IO categorization are not shown due to space <lb/>restriction. <lb/> impact on performance in visual search. Moreover, realistic visual <lb/>metaphors require a higher pixel resolution, and would lose their dis-<lb/>criminating capacity in low resolution conditions. <lb/>Based on the design options shown in Fig. 5, we followed the taxo-<lb/>nomic tree in Fig. 3 and identified the best option for each scheme in <lb/>a hierarchical manner. The evaluation criteria include: <lb/> • the discriminating capacities of different channels (Table 2); <lb/> • metaphoric capacity for aiding learning and remembering; <lb/> • potential conflicts, including spatial, perceptual and metaphoric <lb/>conflicts, with visual channels that have already been assigned to <lb/> S6 | 3 levels <lb/> Design Option 6. <lb/> S6 &gt; S3 | 3 levels <lb/> Design Option 6 <lb/> S6 &gt; S2 | 5 levels <lb/> Design Option 7 <lb/> S6 &gt; S2 &gt; S5 | 7 levels <lb/> Design Option 7 <lb/> S6 &gt; S2 &gt; S4 | 3 levels <lb/> Design Option 5 <lb/> S6 &gt; S2 &gt; S4 &gt; S5 | 7 levels <lb/> Design Option 7 <lb/> S0 | 2 levels <lb/> Design Option 6. <lb/> S7 | 4 levels <lb/> Design Option 1. <lb/> Not detailed in this example. <lb/> more <lb/> Fig. 6. Formation of the final glyph design. Top level items require the <lb/>greatest visual power. It is important to be able to distinguish each of <lb/>the processes based on their parent level in the taxonomy. Distinguish-<lb/>able global shapes provide the difference between IOs (circles) and pro-<lb/>cesses (squares with pointed bottom to indicate directionality). <lb/> other schemes in the tree; <lb/> • encoding costs in terms of requirement for pixel resolution. <lb/>This process normally takes a few iterations, during which new <lb/>design options and new metaphoric abstractions and associations are <lb/>sometimes proposed. <lb/>Based on the hierarchy in Fig. 3, we considered to use color and <lb/>shape options for S0 (IOs vs. processes) and S7 (four classes of IOs). <lb/>As introducing 4 main body shapes to encode IOs is not an effective <lb/>mapping for learning and remembering, we decided to assign outline <lb/>color of the main body to encode S7, and use two basic shapes, circle <lb/>and pentagon (a rectangle with a pointer to show workflow direction) <lb/>to encode S0. Since the main body or the pentagon will only be col-<lb/>ored in black or white, S0 also implicitly encoded in using color sym-<lb/>bolism, that is, color for IOs and black/white for processes. In effect, <lb/>S0 is encoded using two visual channels. This redundancy can serve <lb/>as an error detection in visualization [12]. <lb/>Fig. 6 shows each of the five schemes for the process subtree, and <lb/>the design option chosen from Fig. 5. Below we discuss our reason-<lb/>ing for selecting each of the design options for each scheme in the <lb/>taxonomy. <lb/> S6: Process environment. The taxonomic tree suggested a high <lb/>priority for visual mapping, which is consistent with the domain ex-<lb/>perts&apos; intuition. We took advantage that black color was not used by <lb/>S7 for IOs, we assigned a white background to in silico/in computer <lb/> (related to computational processes), and black to in vivo/in living) <lb/> and in vitro/in glass (related to materials). Further more, we made use <lb/>of a shape-based metaphor, fully-filled background for in vivo (whole <lb/>organism), and black background with white cut out for in vitro (com-<lb/>ponent of an organism). Together, this was given in Fig. 5 as design <lb/>option 6. We maintained the overall appearance of the main body of <lb/>process glyphs in black and white to avoid potential clash with mate-<lb/>rial glyphs. <lb/> S2: Types of Material Manipulation. S2 has 5 classes, and we <lb/>adopted design option 7, which employs visual metaphors that encap-<lb/>sulate strong domain-specific meanings. For example, visual symbol <lb/> molecule <lb/> cellular part <lb/>cell <lb/>tissue <lb/>organ <lb/>organism <lb/>population <lb/> Fig. 7. Visual representations of the 7 classes in S5. <lb/> for the material amplification class depicts a small segment becoming <lb/>a large segment. <lb/> S4: Type of Experimental Perturbation. S4 defines 3 further sub-<lb/>classes of the material perturbation class of S2. Due to the low num-<lb/>ber of subclasses, we made use of line styles to modify the diamond <lb/>shape of the material perturbation. We made metaphoric association <lb/>of three line styles as: &quot; solid &quot; line for physically induced perturbation; <lb/>dash line, a common metaphor for uncertainty and unpredictability, for <lb/>behaviorally induced perturbation; and wavy line, which is closer to a <lb/>circle (a visual signature for IOs), for material induced perturbation. <lb/> S5: Levels of Material Granularity. This scheme has 7 subclasses <lb/>(molecule, cellular part, cell, tissue, organ, organism and population), <lb/>and finding a suitable visual channel was not straightforward. A sim-<lb/>plest approach would be to use colors to fill the interior of the glyph, <lb/>or to use some shape-based encoding. After consulting the domain <lb/>experts, these two options were ruled out. In fact, domain experts <lb/>preferred some pictograms to represent the 7 subclasses. After con-<lb/>sidering a number of more realistic drawings, we found that it was not <lb/>easy to create realistic representations that can differentiate all sub-<lb/>classes (e.g., cellular part vs. cell; organ vs. organism). We designed <lb/>a special set of icons as shown in Fig. 7 with three visual channels <lb/>to aid learning, memorization and recognition. The first visual chan-<lb/>nel is the overall shape and orientation. The second visual channel is <lb/>metaphoric abstraction and association. For example, the shape of cell <lb/>part indicates a portion of a cell. Tissue is associated with a patch, <lb/>organ with an abstract heart shape, organism with an abstract human, <lb/>population with two abstract humans. The third visual channel is the <lb/>number of orange sub-shapes, representing the levels 1-7. <lb/> S3: Types of Data Manipulation. S3 defines a 3 further sub-<lb/>classes of the in silico class of S6. We use three abstract pictograms to <lb/>represent data capture, processing and analysis. The encoding makes <lb/>use of the difference in overall shape, orientation, and number of tri-<lb/>angles to aid learning, memorization and recognition. Note that these <lb/>shapes will not be confused with those for S5 as the white background <lb/>of the main body provides a distinct context of computing rather than <lb/>IOs. <lb/>Following mapping of all schemes to design options, creation of all <lb/>glyphs is a straightforward process. Fig. 8 shows all variations of the <lb/>glyphs associated with the process sub-tree. <lb/>We introduced a &quot; crush &quot; test for the designed glyphs by scaling <lb/>it to different pixel resolutions. Fig. 9 shows some example glyphs <lb/>display at varying resolutions. One can comfortably see all details <lb/>at the 40×40 level. At the 10×10 level, one can observe the visual <lb/>signature of in vivo and in vitro. Even at the lowest level (5×5), one <lb/>can still differentiate the two glyphs. <lb/> 6 WORKFLOW VISUALIZATION AND ISA INTEGRATION <lb/> In order to visualize workflows of biological experiments, we had to <lb/>address the following technical issues: 1) mapping from a name in the <lb/>metadata to a glyph; 2) creating a workflow visualization with both <lb/>node placement and connection display; 3) developing a prototype tool <lb/>for a practical environment such as the ISA tools framework. <lb/>The mapping from concept name is achieved by a look-up table <lb/>which is built from the matrix used in formulating the taxonomic tree <lb/>and implemented as a tab delimited file. Each concept name is mapped <lb/>to a text tag encoding the traversal path from the root of the tree to the <lb/>leaf node corresponding to the name. The tag includes identifiers of <lb/>the schemes and classes encountered. With the path, a glyph can be <lb/>constructed dynamically from the pre-defined visual mapping as de-<lb/>scribed in the previous section. The look-up table also enables storage <lb/>of pre-rendered glyphs in an image format. <lb/> 80px <lb/> 60px <lb/>40px <lb/>20px 10px 5px <lb/> Fig. 9. A &quot; crush &quot; test of glyphs to evaluate the discriminating capacity of <lb/>various visual channels at different resolutions. <lb/> Source Name <lb/>Characteristics[Organism] Protocol REF Sample Name Protocol REF Extract Name <lb/>Label Protocol REF Labeled Extract Name <lb/> source1 <lb/> saccharomyces cerevisiae <lb/>grow <lb/>sample1_grow extraction <lb/>sample1_extract1 biotin labeling <lb/>sample1_extract1_lab1 <lb/>source1 <lb/>saccharomyces cerevisiae <lb/>grow <lb/>sample1_grow extraction <lb/>sample1_extract2 biotin labeling <lb/>sample1_extract2_lab1 <lb/> Fig. 10. A workflow is recorded in text form within the ISA-Tab format. <lb/>Our software translates it to glyph-based visualization. A branching <lb/>event is automatically detected during the translation. <lb/> To generate the workflow, we made use of the layout algorithm <lb/>available within the Prefuse visualization framework [20]. This frame-<lb/>work also brings with it functionality such as panning, zooming and <lb/>filtering which bring more interactivity to the user and making naviga-<lb/>tion through large collections of workflows easier. The only require-<lb/>ment for use of Prefuse was a minimal amount of Java code to create <lb/>the user interface coupled with creation of an XML file format native <lb/>to Prefuse for representation of the tree structure. This XML format <lb/>is configurable, we have configured it to contain: node type (e.g., pro-<lb/>cess), node name (e.g., labeling) and an image to be rendered, which is <lb/>assigned using a look-up operation through the above mentioned tab <lb/>delimited mapping file. The order of the XML elements within this <lb/>file has direct implications on the order these elements are displayed <lb/>in. Within the ISA-Tab format, there is an implicit time element found <lb/>in the ordering of the columns in the study sample and assay files. This <lb/>can be used to construct the XML elements through near direct map-<lb/>pings of processes and IOs, a workflow which is illustrated in Fig. 10. <lb/>Recognizing branching events is an important part of workflow visu-<lb/>alization as illustrated in 10. In software, these branch events can be <lb/>identified when the preceding nodes of a process have the same names <lb/>while the succeeding output nodes are different. Fig. 10 highlights <lb/>one such case, where branching occurs after extraction of 3 materials <lb/>from one sample. <lb/>Our software reads text-based ISA-Tab files as illustrated to create <lb/>the XML notations required by Prefuse for rendering the experiment <lb/>workflow illustrated in Fig. 1(b). <lb/>The software is implemented as a Java application capable of pro-<lb/>cessing ISA-Tab files to create experimental workflows using glyphs. <lb/>For the purposes of broad dissemination in the near future, we have in-<lb/>tegrated the workflow visualization directly inside ISAcreator, a Java <lb/>desktop application for creating and editing ISA-Tab files. Further-<lb/>more, the standalone workflow visualization shown in figures 11a and <lb/>b makes use of the same ISA-Tab parser as available within ISAcre-<lb/> C1 on material <lb/> C2 on data <lb/> C1 data acquisition <lb/> C2 data preprocessing <lb/> C3 data analysis <lb/> C1 material perturbation <lb/> C2 material combination <lb/> C3 material amplification <lb/> C4 material separation <lb/> C5 material collection <lb/> C1 behaviourally induced perturbation <lb/> C2 physically induced perturbation <lb/> C3 material induced perturbation <lb/> C1 input molecular part <lb/> C2 input cellular component <lb/> C3 input cell <lb/> C4 input tissue <lb/> C5 input organ <lb/> C6 input organism <lb/> C7 input population <lb/> C1 in vitro <lb/> C2 in silico <lb/> C3 in vivo <lb/> C1 biological <lb/> C2 device <lb/> C3 chemical <lb/> C4 data <lb/>C1 inputs and outputs <lb/>C2 processes <lb/> Schemes &amp; classifications <lb/> Fig. 8. Overview of the taxonomy based glyph designs in the context of biodomain. <lb/>Fig. 11. User can interact with a workflow to view the text descriptions <lb/>of individual glyphs in pop-up windows, which are also dynamic legends <lb/>showing how the concept is categorized and how the corresponding <lb/>glyph is decomposed into different elementary visual representations. <lb/>Users can also use such a legend to find out other classes in a catego-<lb/>rization scheme. <lb/> ator. The integration involved the development of user interface el-<lb/>ements for ISAcreator software to access the workflow visualization. <lb/>From the spreadsheet view, users may highlight rows (assays), right <lb/>click and select an option named &quot; View workflow for assays &quot; to visu-<lb/>alize the entire processing pipeline for the corresponding samples as <lb/>shown in Fig. 1(b). <lb/> 7 CONCLUSIONS AND FUTURE WORK <lb/> Although it was established in psychology that people can learn rules <lb/>of glyph encoding consciously as well as unconsciously [16], we do <lb/>not expect users to learn and remember these glyphs without help. We <lb/>thus allow users to find detailed text descriptions in pop-up windows <lb/>interactively. As shown in Fig. 11, not only do these windows pro-<lb/>vide names of processes and IOs, they also serve as dynamic legends, <lb/>showing how each glyph is decomposed into different elements corre-<lb/>sponding to categorization schemes. One can also select a component <lb/>to view all classes in a scheme. <lb/>In this manuscript, we presented a systematic approach for glyph <lb/>design by using taxonomy as a guide. We demonstrated our approach <lb/>by analyzing the content of a biological database and showed how our <lb/>tree-building algorithm could be used to take a large collection of con-<lb/>cepts and generate a taxonomic tree, which provides an ordering of a <lb/>set of categorization schemes (i.e., attribute dimensions). This enabled <lb/>us to draw a parallel between the ordering of attribute dimensions with <lb/>the ordering of visual channels compiled from the perception and visu-<lb/>alization literature. We involved domain experts in refining the tree as <lb/>well as in creating metaphoric abstraction and association for glyphs. <lb/>This work was followed by development of a prototype tool for glyph-<lb/>based visualization of experimental design workflows as found in bi-<lb/>ology. The prototype is integrated in the ISA suite of tools to be dis-<lb/>seminated to users. <lb/>We plan to further the present work to include the provision of <lb/> &quot; macros &quot; in workflows in order to make graphs more compact and <lb/>create dynamic web-based rendering of the workflows using vector <lb/>graphics. We also intend to carry out field-based evaluation through <lb/>ISAcommons, the user community of ISA-tools framework. Like all <lb/>potential diagrammatic schemes, we expect that it will take many iter-<lb/>ations before it can become a standard. Nevertheless, the development <lb/>of an online visualization tool will make such a process more efficient. <lb/> ACKNOWLEDGMENTS <lb/> This work was supported by funding from the BBSRC and NERC, <lb/>grants BB/I000917/1 and BB/I025840/1. <lb/></body>

			<listBibl> REFERENCES <lb/> [1] Arrayexpress. http://www.ebi.ac.uk/arrayexpress/. <lb/>[2] Gene expression omnibus (geo). http://www.ncbi.nlm.nih.gov/geo/. <lb/>[3] Graphviz. http://graphviz.org/. <lb/>[4] R. Abdullah and R. Hümber. Pictograms, Icons &amp; Signs: A guide to <lb/>Information Graphics. Thames &amp; Hudson, 2006. <lb/>[5] M. Bar. Visual objects in context. Nature reviews. Neuroscience, <lb/> 5(8):617–629, 2004. <lb/>[6] P. Barker and J. Fraser. Sign design guide: a guide to inclusive signage. <lb/> JMU and Sign Design Society, 2000. <lb/>[7] J. Bertin. Semiology of graphics: diagrams, networks, maps. University <lb/>of Wisconsin press, 1983. <lb/>[8] R. Borgo, A. Abdul-Rahman, F. Mohamed, P. W. Grant, I. Reppa, <lb/>L. Floridi, and M. Chen. An empirical study on using visual embellish-<lb/>ments in visualization. to appear in IEEE Transactions on Visualization <lb/>and Computer Graphics, 2012. <lb/>[9] R. Bourqui and M. Westenberg. Visualizing temporal dynamics at the <lb/>genomic and metabolic level. Proc. 13th Int. Conf. Information Visuali-<lb/>sation, pages 317–322, 2009. <lb/>[10] B. Burns, B. E. Shepp, D. McDonough, and W. K. Wiener-Ehrlich. The <lb/>relation between stimulus analyzability and perceived dimensional struc-<lb/>ture. The Psychology of Learning and Motivation, pages 77–115, 1978. <lb/>[11] Y. Cai, M. L. Wilson, and J. Peccoud. Genocad for igem: a grammatical <lb/>approach to the design of standard-compliant constructs. Nucleic Acids <lb/>Res, 38(8):2637–44, May 2010. <lb/>[12] M. Chen and H. Jänicke. An information-theoretic framework for visu-<lb/>alization. IEEE Transactions on Visualization and Computer Graphics, <lb/> 16(6):1206–1215, 2010. <lb/>[13] M. Chuah and S. Eick. Information rich glyphs for software management <lb/>data. IEEE Computer Graphics and Applications, 18:24–29, 1998. <lb/>[14] T. Czauderna, C. Klukas, and F. Schreiber. Editing, validating and trans-<lb/>lating of sbgn maps. Bioinformatics, 26(18):2340–2341, 2010. <lb/>[15] J. Duncan and G. Humphreys. Visual search and stimulus similarity. Psy-<lb/>chological review, 96(3):433–491, 1989. <lb/>[16] J. Franks and J. Bransford. Abstraction of visual patterns. Journal of <lb/>experimental psychology, 90(1):65–139, 1971. <lb/>[17] M. Green. Toward a perceptual science of multidimensional data visual-<lb/>ization: Bertin and beyond. ERGO/GERO Human Factors Science, 1998. <lb/>[18] S. Handelt and S. Imai. The free classification of analyzable and unana-<lb/>lyzable stimuli. Attention, Perception, &amp; Psychophysics, 12(1):108–224, <lb/>1972. <lb/>[19] C. G. Healey and J. T. Enns. Attention and visual memory attention and <lb/>visual memory in visualization and computer graphics. IEEE Transac-<lb/>tions on Visualization and Computer Graphics, 18(7):1170–1188, 2011. <lb/>[20] J. Heer, S. K. Card, and J. A. Landay. prefuse: A toolkit for interactive <lb/>information visualization. In Proc. ACM CHI, pages 421–430, 2005. <lb/>[21] K. Hemenway. Psychological issues in the use of icons in command <lb/>menus. In Proc. ACM CHI, pages 20–23, 1982. <lb/>[22] B. H. Junker, C. Klukas, and F. Schreiber. Vanted: A system for ad-<lb/>vanced data analysis and visualization in the context of biological net-<lb/>works. BMC Bioinformatics, 2006. <lb/>[23] A. Karve and M. Gleicher. Glyph-based overviews of large datasets in <lb/>structural bioinformatics. In Proc. 11th Int. Conf. Information Visualiza-<lb/>tion, Supplements, pages 1–6, 2007. <lb/>[24] R. Kinchla and J. Wolfe. The order of visual processing: &quot; top-down, &quot; <lb/> &quot; bottom-up &quot; , or &quot; middle-out &quot; . Perception &amp; psychophysics, 25(3), 1979. <lb/>[25] G. Kindlmann and C.-F. Westin. Diffusion tensor visualization with glyph <lb/>packing. IEEE Transactions on Visualization and Computer Graphics, <lb/> 12(5):1329–1335, 2006. <lb/>[26] D. Krantz and A. Tversky. Similarity of rectangles: An analysis of sub-<lb/>jective dimensions. Journal of Mathematical Psychology, 12(1), 1975. <lb/>[27] R. Krishnapuram and K. Kummamuru. Automatic taxonomy generation: <lb/>Issues and possibilities. In Proc. IFSA 2003, LNCS, pages 184–195, 2003. <lb/>[28] N. Le Noère, M. Hucka, H. Mi, S. Moodie, and et al. The systems <lb/>biology graphical notation. Nat Biotechnol, 27(8), 2009. <lb/>[29] J. P. Lewis and R. Rosenholtz. VisualIDs: Automatic distinctive icons <lb/>for desktop interfaces. ACM Transactions on Graphics, 23(3):416–423, <lb/>2004. <lb/>[30] B. Love, J. Rouder, and E. Wisniewski. A structural account of global <lb/>and local processing. Cognitive psychology, 38(2):291–607, 1999. <lb/>[31] S. Luck and S. Hillyard. Electrophysiological correlates of feature anal-<lb/>ysis during visual search. Psychophysiology, 31(3):291–308, 1994. <lb/>[32] E. Maguire. Taxonomy in biology and visualization. http: //isa-<lb/>tab.sourceforge.net/docs/publications/Taxonomy.pdf, Jan 2012. <lb/>[33] S. McDougall, O. De Bruijn, and M. Curry. Exploring the effects of <lb/>icon characteristics on user performance: The role of icon concreteness, <lb/>complexity, and distinctiveness. Journal of Experimental Psychology: <lb/>Applied, 6(4), 2000. <lb/>[34] P. Muter and D. Mayson. The role of graphics in item selection from <lb/>menus. Behaviour and Information Technology, 5:89–95, 1986. <lb/>[35] D. Navon. Forest before trees: The precedence of global features in visual <lb/>perception. Cognitive psychology, 9(3):353–736, 1977. <lb/>[36] D. A. Norman. The Design of Everyday Things. Basic Books, 2002. <lb/>[37] H. Ogata, S. Goto, K. Sato, W. Fujibuchi, H. Bono, and M. Kanehisa. <lb/>Kegg: Kyoto encyclopedia of genes and genomes. NAR, 27(1), 1999. <lb/>[38] S. Palmer. Hierarchical structure in perceptual representation. Cognitive <lb/>Psychology, 9(4):441–915, 1977. <lb/>[39] D. Parkhurst, K. Law, and E. Niebur. Modeling the role of salience in the <lb/>allocation of overt visual attention. Vision research, 42(1), 2002. <lb/>[40] J. K. Patel and C. B. Read. Handbook of the Normal Distribution. Marcel <lb/>Dekker, 2nd edition, 1996. <lb/>[41] J. W. Pellegrino, R. R. Rosinski, H. L. Chiesi, and A. Siegel. Picture-word <lb/>differences in decision latency: An analysis of single and dual memory <lb/>models. Memory and Cognition, 5:383–396, 1977. <lb/>[42] F. Post, T. Walsum, F. Post, and D. Silver. Iconic techniques for feature <lb/>visualization. Proc. IEEE Visualization, pages 288–295, 1995. <lb/>[43] P. Quinlan. Visual feature integration theory: past, present, and future. <lb/> Psychological bulletin, 129(5):643–716, 2003. <lb/>[44] P. Quinlan and G. Humphreys. Visual search for targets defined by <lb/>combinations of color, shape, and size: an examination of the task con-<lb/>straints on feature and conjunction searches. Perception &amp; psychophysics, <lb/> 41(5):455–527, 1987. <lb/>[45] W. Ribarsky, E. Ayers, and J. Eble. Glyphmaker: creating customized <lb/>visualizations of complex data. Computer, 27:57–64, 1994. <lb/>[46] P. Rocca-Serra, E. Maguire, S.-A. Sansone, and et al. Isa software suite: <lb/>supporting standards-compliant experimental annotation and enabling cu-<lb/>ration at the community level. Bioinformatics, 26(18), 2010. <lb/>[47] Rohrer and et al. The shape of shakespeare: visualizing text using implicit <lb/>surfaces. In Proc. IEEE Visualization, pages 121–129, 1998. <lb/>[48] T. Ropinski, S. Oeltze, and B. Preim. Survey of glyph-based visualization <lb/>techniques for spatial multivariate medical data. Computers &amp; Graphics, <lb/> 35(2):392 – 401, 2011. <lb/>[49] D. E. Rumelhart. A multicomponent theory of the perception of briefly <lb/>exposed visual displays. Journal of Math. Psych., 7(2):191–218, 1970. <lb/>[50] S.-A. Sansone, P. Rocca-Serra, D. Field, E. Maguire, and et al. Toward <lb/>interoperable bioscience data. Nat Genet, 44(2):121–6, 2012. <lb/>[51] R. Shepard. Attention and the metric structure of the stimulus space. <lb/> Journal of Mathematical Psychology, 1(1):54–141, 1964. <lb/>[52] H. Siirtola. The effect of data-relatedness in interactive glyphs. In Proc. <lb/>9th Int. Conf. Information Visualization, 2002. <lb/>[53] G. Sperling. The information available in brief visual presentations. Psy-<lb/>chological Monographs: General and Applied, 74(11):1–29, 1960. <lb/>[54] K. T. Spoehr and S. W. Lehmkuhle. Visual Information Processing. W. <lb/>H. Freeman &amp; Company, 1982. <lb/>[55] A. Treisman. Focused attention in the perception and retrieval of multidi-<lb/>mensional stimuli. Attention, Perception, &amp; Psychophysics, 22(1), 1977. <lb/>[56] A. Treisman and S. Gormican. Feature analysis in early vision: evidence <lb/>from search asymmetries. Psychol Rev, 95(1):15–48, Jan 1988. <lb/>[57] Q. Wang, P. Cavanagh, and M. Green. Familiarity and pop-out in visual <lb/>search. Percept Psychophys, 56(5):495–500, Nov 1994. <lb/>[58] M. O. Ward. Multivariate data glyphs: Principles and practice. In Hand-<lb/>book of Data Visualization, pages 179–198. 2008. <lb/>[59] C. Ware. Information Visualization: Perception for Design. Morgan <lb/>Kaufmann, 2004. <lb/>[60] S. Wiedenbeck. The use of icons and labels in an end user application <lb/>program: an empirical study of learning and retention. Behavior and <lb/>Information Technology, 18(2):68–82, 1999. <lb/>[61] L. Williams. The effects of target specification on objects fixated during <lb/>visual search. Acta psychologica, 27:355–415, 1967. <lb/>[62] C. Wittenbrink, A. Pang, and S. Lodha. Glyphs for visualizing uncer-<lb/>tainty in vector field. IEEE Transactions on Visualization and Computer <lb/>Graphics, 2:266–279, 1996. <lb/>[63] J. Wolfe, K. Cave, and S. Franzel. Guided search: an alternative to the <lb/>feature integration model for visual search. Journal of experimental psy-<lb/>chology. Human perception and performance, 15(3):419–452, 1989. </listBibl>


	</text>
</tei>
